{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1279621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cil.framework import AcquisitionGeometry, ImageGeometry\n",
    "from cil.io import NEXUSDataWriter\n",
    "from cil.plugins.astra.processors import FBP\n",
    "from cil.plugins.astra.operators import ProjectionOperator\n",
    "from cil.utilities.display import show2D\n",
    "from utils import download_zenodo\n",
    "\n",
    "from cil.optimisation.algorithms import PDHG\n",
    "from cil.optimisation.operators import BlockOperator, GradientOperator, ZeroOperator, FiniteDifferenceOperator, IdentityOperator\n",
    "from cil.optimisation.functions import L2NormSquared, L1Norm, MixedL21Norm, BlockFunction, IndicatorBox, ZeroFunction\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8449f31c",
   "metadata": {},
   "source": [
    "**First we need to download the raw data files used for reconstruction from [Zenodo](https://zenodo.org/record/5825464). For the powder phantom, there are three main datasets:**\n",
    "\n",
    "1) powder_phantom_180s_sinogram.mat (Matlab file for Scan A dataset of 180 projections, 180s exposure time. The dataset has already been flatfield corrected).\n",
    "\n",
    "2) powder_phantom_30s_sinogram.mat (Matlab file for Scan B dataset of 30 projections, 30s exposure time. The dataset has already been flatfield corrected).\n",
    "\n",
    "3) Energy_axis.mat (Matlab file providing the direct energy-channel conversion, useful for analysing reconstructed datasets at different channels or different energies).\n",
    "\n",
    "This may take some time.  \n",
    "\n",
    "**Note:** The `download_zenodo` function requires the `wget` python package to access Zenodo files. If you don't have it, you can install using the command `conda install -c conda-forge python-wget`.\n",
    "\n",
    "**Note 2:** You can skip this part if you already downloaded the powder data from the accompanying script `Powder_Phantom_180s_180Proj_FDK.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed6c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_zenodo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67400ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Read data for Scan B datasets\n",
    "pathname = os.path.abspath(\"MatlabData/\")\n",
    "\n",
    "# Scan B dataset - 30s, 30 projections\n",
    "datafile = \"Powder_phantom_30s_30Proj_sinogram.mat\"\n",
    "\n",
    "path = os.path.join(pathname,datafile)\n",
    "\n",
    "tmp_X = sio.loadmat(path)   \n",
    "X = tmp_X['S_30_30']\n",
    "\n",
    "# Read Energy-Channel conversion\n",
    "tmp_energy_channels = sio.loadmat(pathname + \"/Energy_axis.mat\")\n",
    "ekeV = tmp_energy_channels['E_axis']\n",
    "ekeV_crop = ekeV[0][99:199]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0ab947",
   "metadata": {},
   "source": [
    "Sinogram raw data shape is [Vertical, Angles, Horizontal, Channels].  \n",
    "However we need it in the shape [Channels, Vertical, Angles, Horizontal].  \n",
    "We reorder using `np.swapaxes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a7a862",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original Shape: {}'.format(X.shape))\n",
    "X = np.swapaxes(X, 0, 3)\n",
    "X = np.swapaxes(X, 1, 2)\n",
    "print('Reordered Shape: {}'.format(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c52fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Crop and rotate data to match data in paper\n",
    "\n",
    "X = X[99:199] # Crop data to reduced channel subset (channels 100-200)\n",
    "X = np.transpose(X,(0,3,2,1)) # Rotate data\n",
    "print('Reduced Shape: {}'.format(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65071752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Data shape information\n",
    "num_channels = X.shape[0]\n",
    "horizontal = X.shape[3]\n",
    "vertical = X.shape[1]\n",
    "num_angles = X.shape[2]\n",
    "\n",
    "angles = np.linspace(-180+45,180+45,num_angles,endpoint=False)*np.pi/180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1b4621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Define imaging scan metadata\n",
    "\n",
    "# Scan parameters\n",
    "distance_source_center = 318.0  # [mm]\n",
    "distance_center_detector = 492.0  # [mm]\n",
    "detector_pixel_size = 0.25  # [mm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1075e3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Define AcquisitionGeometry from imaging scan parameters\n",
    "\n",
    "ag = AcquisitionGeometry.create_Cone3D(source_position = [0,-distance_source_center,0],\n",
    "                                       detector_position = [0,distance_center_detector,0])\\\n",
    "                                     .set_panel([horizontal,vertical],[detector_pixel_size,detector_pixel_size])\\\n",
    "                                     .set_channels(num_channels)\\\n",
    "                                     .set_angles(-angles,angle_unit=\"radian\")\\\n",
    "                                     .set_labels(['channel', 'vertical', 'angle', 'horizontal'])\n",
    "\n",
    "# Create the 4D acquisition data\n",
    "data = ag.allocate()\n",
    "data.fill(X)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0470400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ImageGeometry directly from the AcquisitionGeometry using ig = ag.get_ImageGeometry()\n",
    "\n",
    "ig = ag.get_ImageGeometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20024f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the tomography operator for 3D hyperspectral data using the AcquisitionGeometry and ImageGeometry\n",
    "\n",
    "ag3D = ag.get_slice(channel=0)\n",
    "ig3D = ag3D.get_ImageGeometry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239e62c4",
   "metadata": {},
   "source": [
    "## FDK Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809e3455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate space for the FBP_4D recon\n",
    "\n",
    "FBP_recon_4D = ig.allocate()\n",
    "\n",
    "t = time.time()\n",
    "        \n",
    "# FBP reconstruction per channel\n",
    "for i in range(ig.channels):\n",
    "    \n",
    "    FBP_recon_3D = FBP(ig3D, ag3D, 'gpu')(data.get_slice(channel=i))\n",
    "    FBP_recon_4D.fill(FBP_recon_3D, channel=i)\n",
    "    \n",
    "    print(\"Finish FBP recon for channel {}\".format(i), end='\\r')\n",
    "    \n",
    "print(\"\\nFDK Reconstruction Complete!\")\n",
    "tot = time.time() - t\n",
    "print('Runtime: {} s'.format(tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d0c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test image\n",
    "\n",
    "plt.imshow(FBP_recon_4D.as_array()[50,40,:,:],cmap='inferno',vmin=0.0,vmax=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba77f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Save as nxs file with NEXUSDataWriter\n",
    "\n",
    "name = \"Powder_30s_30Proj_FDK.nxs\"\n",
    "writer = NEXUSDataWriter(file_name = \"HyperspectralData/\" + name,\n",
    "                         data = FBP_recon_4D)\n",
    "writer.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b966e132",
   "metadata": {},
   "source": [
    "## PDHG Reconstruction with Space TV and Channel TGV Regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1da1faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Set up AstraProjector for 3D Multi-channel dataset\n",
    "\n",
    "A3DMC = ProjectionOperator(ig, ag, 'gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e546dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Block Operator for combined Space TV - Channel TGV regularisation\n",
    "\n",
    "op11 = GradientOperator(ig, correlation='Space', backend = \"numpy\")\n",
    "op12 = ZeroOperator(ig, op11.range_geometry())\n",
    "\n",
    "op21 = FiniteDifferenceOperator(ig, direction = 0)\n",
    "op22 = -IdentityOperator(ig)\n",
    "\n",
    "op31 = ZeroOperator(ig)\n",
    "op32 = FiniteDifferenceOperator(ig, direction = 0)\n",
    "\n",
    "op41 = A3DMC\n",
    "op42 = ZeroOperator(ig, ag)\n",
    "\n",
    "operator = BlockOperator(op11, op12, \n",
    "                         op21, op22, \n",
    "                         op31, op32, \n",
    "                         op41, op42, shape=(4,2))\n",
    "\n",
    "# Compute operator Norm\n",
    "normK = operator.norm()\n",
    "\n",
    "sigma = 1./normK\n",
    "tau = 1./normK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a4b6b6",
   "metadata": {},
   "source": [
    "## Set up and run PDHG TV-TGV algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876800d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set regularisation weighting parameters\n",
    "\n",
    "alpha = 0.002\n",
    "beta = 0.18\n",
    "gamma = np.sqrt(2) * beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824b28b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build BlockFunction\n",
    "\n",
    "f1 = alpha * MixedL21Norm()\n",
    "f2 = beta * L1Norm() \n",
    "f3 = gamma * L1Norm()\n",
    "f4 = 0.5 * L2NormSquared(b=data)\n",
    "\n",
    "f = BlockFunction(f1, f2, f3, f4)         \n",
    "g = BlockFunction(IndicatorBox(lower=0),ZeroFunction())  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cafe01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run reconstruction algorithm for 1000 iterations\n",
    "\n",
    "t = time.time()\n",
    "\n",
    "# Run the PDHG algorithm\n",
    "print(alpha, beta, gamma)  \n",
    "pdhg = PDHG(f=f, g=g, operator=operator, tau=tau, sigma=sigma, \n",
    "            max_iteration = 2000 , update_objective_interval = 100)        \n",
    "pdhg.run(1000, verbose = 1)\n",
    "        \n",
    "print('Finished!')\n",
    "tot = time.time() - t\n",
    "print('Runtime: {} s'.format(tot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156130d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test image\n",
    "\n",
    "plt.imshow(pdhg.solution[0].as_array()[50,40,:,:],cmap='inferno',vmin=0.0,vmax=3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5e9d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save result as nxs file with NEXUSDataWriter\n",
    "\n",
    "name = \"{}_iters_alpha_{}_beta_{}.nxs\".format(pdhg.iteration,alpha,beta)\n",
    "writer = NEXUSDataWriter(file_name=\"HyperspectralData/\" + name,\n",
    "                        data = pdhg.solution[0])\n",
    "writer.write()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
